{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d557b0ab-62f7-4d6e-ab08-3617b93b53e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\daoth\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\daoth\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daoth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: python-docx, PyPDF2, sentence-transformers\n",
      "Successfully installed PyPDF2-3.0.1 python-docx-1.1.2 sentence-transformers-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 python-docx sentence-transformers numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2a14ec-6918-436a-80ec-be0ff4dbb7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đoạn trích mẫu từ văn bản pháp luật:\n",
      " \n",
      "NGHỊ QUYẾT\n",
      "Hướng dẫn áp dụng pháp luật trong việc giải quyết\n",
      " các vụ án dân sự, hôn nhân và gia đình\n",
      "HỘI ĐỒNG THẨM PHÁN TOÀ ÁN NHÂN DÂN TỐI CAO\n",
      "Căn cứ vào Luật Tổ chức Toà án nhân dân;\n",
      "Để thi hành đúng và thống nhất các quy định của pháp luật trong việc giải quyết các vụ án dân sự, hôn nhân và gia đình;\n",
      "Sau khi có ý kiến thống nhất của Bộ trưởng Bộ Tư pháp và Viện trưởng Viện kiểm sát nhân dân tối cao,\n",
      "QUYẾT ĐỊNH\n",
      "I. VIỆC ÁP DỤNG CÁC QUY ĐỊNH CỦA PHÁP LUẬT VỀ THỜI HIỆU\n",
      "1. Việc áp dụng các quy đ\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Trích xuất văn bản từ file PDF\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file PDF: {e}\")\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"Trích xuất văn bản từ file DOCX\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file DOCX: {e}\")\n",
    "    return text\n",
    "    \n",
    "docx_text = extract_text_from_docx(\"02.2004.NQ.HDTP.docx\")\n",
    "\n",
    "# Kết hợp văn bản từ cả hai nguồn\n",
    "combined_text = docx_text\n",
    "print(\"Đoạn trích mẫu từ văn bản pháp luật:\")\n",
    "print(combined_text[:500])  # In 500 ký tự đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9baddf-1bb3-4a97-82ba-077d6c47c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số đoạn trích thu được: 112\n"
     ]
    }
   ],
   "source": [
    "def split_into_paragraphs(text, min_length=20):\n",
    "    \"\"\"Tách văn bản thành các đoạn, chỉ giữ những đoạn có độ dài >= min_length ký tự\"\"\"\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\") if len(p.strip()) >= min_length]\n",
    "    return paragraphs\n",
    "\n",
    "paragraphs = split_into_paragraphs(combined_text)\n",
    "print(\"Số đoạn trích thu được:\", len(paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6938494-8897-4f4a-b1c4-101f3b8014cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.0.5-cp37-abi3-win_amd64.whl.metadata (498 bytes)\n",
      "Downloading hf_xet-1.0.5-cp37-abi3-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.3/4.2 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.9/4.2 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5122635c-f26a-4cb7-a52f-ed114bd3dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo embeddings cho các đoạn trích...\n",
      "Xong tạo embeddings cho 112 đoạn văn.\n",
      "\n",
      "Kết quả tìm kiếm:\n",
      "1. Xác định quyền sử dụng đất là di sản\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Tải mô hình embeddings phù hợp cho tiếng Việt\n",
    "embed_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Tạo embeddings cho tất cả các đoạn văn bản trích được\n",
    "print(\"Đang tạo embeddings cho các đoạn trích...\")\n",
    "paragraph_embeddings = embed_model.encode(paragraphs, convert_to_tensor=True)\n",
    "print(\"Xong tạo embeddings cho\", len(paragraphs), \"đoạn văn.\")\n",
    "\n",
    "def retrieve_information(query, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Dựa trên câu hỏi của người dùng, tìm ra đoạn văn bản có cosine similarity cao nhất.\n",
    "    Nếu điểm tương đồng thấp hơn ngưỡng threshold thì trả lời không tìm thấy thông tin phù hợp.\n",
    "    \"\"\"\n",
    "    query_embedding = embed_model.encode(query, convert_to_tensor=True)\n",
    "    cosine_scores = util.cos_sim(query_embedding, paragraph_embeddings)[0]\n",
    "    best_idx = int(torch.argmax(cosine_scores))\n",
    "    best_score = cosine_scores[best_idx].item()\n",
    "    \n",
    "    if best_score < threshold:\n",
    "        return \"Xin lỗi, tôi không tìm thấy thông tin phù hợp trong văn bản pháp luật.\"\n",
    "    else:\n",
    "        return paragraphs[best_idx]\n",
    "\n",
    "# Test ví dụ:\n",
    "test_query = \"Quy định chuyển giao quyền sử dụng đất thừa kế như thế nào?\"\n",
    "result = retrieve_information(test_query)\n",
    "print(\"\\nKết quả tìm kiếm:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33aa514c-2c49-4346-8e09-9b1e6717203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot tư vấn luật pháp đã sẵn sàng. Gõ 'exit' hoặc 'thoát' để kết thúc cuộc trò chuyện.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Bạn:  Ai được quyền thừa kế đất đai theo pháp luật Việt Nam?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: - Đất không bị Nhà nước quản lý trong quá trình thực hiện chính sách đất đai của Nhà nước Việt Nam dân chủ cộng hoà, Chính phủ cách mạng lâm thời Cộng hoà miền Nam Việt Nam và Nhà nước Cộng hoà xã hội chủ nghĩa Việt Nam;\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Bạn:  Nếu có người bị mất tích trong hàng thừa kế thì phải làm sao?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: b. Trường hợp người chết để lại di sản cho các thừa kế nhưng các thừa kế không trực tiếp quản lý, sử dụng mà di sản đó đang do người khác chiếm hữu bất hợp pháp hoặc thuê, mượn, quản lý theo uỷ quyền... thì các thừa kế có quyền khởi kiện người khác đó để đòi lại di sản.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Bạn:  thoát\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Cảm ơn bạn đã sử dụng dịch vụ!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChatbot tư vấn luật pháp đã sẵn sàng. Gõ 'exit' hoặc 'thoát' để kết thúc cuộc trò chuyện.\")\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"\\nBạn: \")\n",
    "    if user_query.lower() in ['exit', 'thoát']:\n",
    "        print(\"Chatbot: Cảm ơn bạn đã sử dụng dịch vụ!\")\n",
    "        break\n",
    "    answer = retrieve_information(user_query)\n",
    "    print(\"Chatbot:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b0b7c-c5ba-4ecf-af2b-c5ad06a2e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
